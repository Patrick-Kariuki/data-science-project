{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861e5649-a10f-4d60-afe6-9d2b88e04e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e2b8e0-f1db-47f5-8aeb-1628c6c11342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the JSON file\n",
    "json_file = 'data&labels.json'\n",
    "with open(json_file, 'r') as f:\n",
    "    image_dict = json.load(f)\n",
    "\n",
    "# Load images and labels from the dictionary\n",
    "image_paths, labels = zip(*image_dict.items())\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Load images and resize them to a fixed size\n",
    "images = []\n",
    "for image_path in image_paths:\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (100, 100))  # Resize to 100x100 (adjust as needed)\n",
    "    images.append(img)\n",
    "\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8433ea3b-022f-4272-8bb3-2349689cefa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 10:38:23.377187: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 5s 198ms/step - loss: 1.5460 - accuracy: 0.3204 - val_loss: 1.5422 - val_accuracy: 0.3301\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 5s 192ms/step - loss: 1.2293 - accuracy: 0.5158 - val_loss: 1.3851 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.9635 - accuracy: 0.6153 - val_loss: 1.3765 - val_accuracy: 0.4515\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 5s 198ms/step - loss: 0.7455 - accuracy: 0.7269 - val_loss: 1.4669 - val_accuracy: 0.4660\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 5s 193ms/step - loss: 0.4111 - accuracy: 0.8495 - val_loss: 1.7136 - val_accuracy: 0.4466\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 5s 188ms/step - loss: 0.2432 - accuracy: 0.9163 - val_loss: 1.9477 - val_accuracy: 0.5097\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 5s 189ms/step - loss: 0.1233 - accuracy: 0.9648 - val_loss: 2.0560 - val_accuracy: 0.4951\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 5s 195ms/step - loss: 0.0773 - accuracy: 0.9806 - val_loss: 2.5645 - val_accuracy: 0.4660\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 5s 200ms/step - loss: 0.0748 - accuracy: 0.9818 - val_loss: 2.9467 - val_accuracy: 0.4466\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 5s 192ms/step - loss: 0.0742 - accuracy: 0.9733 - val_loss: 2.6863 - val_accuracy: 0.4369\n",
      "7/7 [==============================] - 0s 52ms/step - loss: 2.6863 - accuracy: 0.4369\n",
      "Loss: 2.686317205429077, Accuracy: 0.43689319491386414\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # Assuming 5 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77475852-cfbe-4c1a-ac41-e8823aba944f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
